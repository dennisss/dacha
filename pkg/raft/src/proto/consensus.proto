syntax = "proto3";

package raft;

import "third_party/google/src/proto/empty.proto";
import "pkg/raft/src/proto/ident.proto";
import "pkg/raft/src/proto/consensus_state.proto";

// Internal RPC Server between servers participating in the consensus protocol
service Consensus {
	rpc PreVote (RequestVoteRequest) returns (RequestVoteResponse);

	// Sent from a candiate server to all other servers to request a vote for the candidate
	// to become the new leader. 
	rpc RequestVote (RequestVoteRequest) returns (RequestVoteResponse);
	
	// Sent from the current leader to followers to replicate new log entries.
	rpc AppendEntries (AppendEntriesRequest) returns (AppendEntriesResponse);
	
	rpc TimeoutNow (TimeoutNow) returns (google.protobuf.Empty);

	rpc InstallSnapshot (stream InstallSnapshotRequest) returns (stream InstallSnapshotResponse);

    // This is the odd ball out internal client method
    // NOTE: 'AddServer' and 'RemoveServer' will be implemented by clients in
    // terms of this method
	rpc Propose (ProposeRequest) returns (ProposeResponse);

	// Lookups up the current status of this server.
	rpc CurrentStatus (google.protobuf.Empty) returns (Status);
}

message RequestVoteRequest {
	RequestId request_id = 5;

	// Candidate's term.
	// This will be the term in which the candidate is elected to be leader (if successful). This
	// should be selected to be greater than all previously seen terms.  
	// REQUIRED
    Term term = 1;

	// REQUIRED
    ServerId candidate_id = 2; /* < TODO: This doesn't 'need' to be sent if we pre-establish
                                 * this server's identity and on the connection layer and we are
                                 * not proxying a request for someone else */
    
	// REQUIRED
	LogIndex last_log_index = 3;
	
	// REQUIRED
	Term last_log_term = 4;
}

message RequestVoteResponse {
	RequestId request_id = 3;

	// REQUIRED
	Term term = 1; /* < If granted then this is redundant as it will only ever grant a vote for
                     * the same up-to-date term */

	// REQUIRED
	bool vote_granted = 2;
}

// Represents a change to the cluster configuration in some configuration (in
// particular, this is for the case of membership changes one server at a time)
// If a change references a server already having some role in the cluster,
// then it is invalid
// In order for a config change to be appended to the leader's log for
// replication, all previous config changes in the log must also commited
// (although this is realistically only necessary if the change is to or from
// that of a full voting member)
message ConfigChange {
	oneof type {
		ServerId AddMember = 1;

		// Adds a server as a learner: meaning that entries will be replicated to
		// this server but it will not be considered for the purposes of elections
		// and counting votes.
		ServerId AddLearner = 2;

		// Removes a server completely from either the learners or members pools
		ServerId RemoveServer = 3;
	}
}

message LogPosition {
	// REQUIRED
    LogIndex index = 1;

	// REQUIRED
    Term term = 2;
}

// The format of a single log entry that will be appended to every server's
// append-only log
//
// Each entry represents an increment by one of the current log index
//
// TODO: Over the wire, the term number can be skipped if it is the same as the
// current term of the whole message of is the same as a previous entry
message LogEntry {
	// REQUIRED
	LogPosition pos = 1;

	// REQUIRED
	LogEntryData data = 2;
}

message LogEntryData {
	oneof type {
		// Does nothing but occupies a single log index
		// Currently this is used for getting a unique marker from the log index
		// used to commit this entry
		// In particular, we use these log indexes to allocate new server ids
		bool noop = 1;

		// Used internally for managing changes to the configuration of the cluster
		ConfigChange config = 2;

		// Represents some opaque data to be executed on the state machine
		bytes command = 3; /* TODO: Other potentially useful operations
                       * Commit, VoteFor, ObserveTerm <- These would be just for potentially
                       * optimizing out writes to the config/meta files and only ever writing
                       * consistently to the log file */
	}
}


message AppendEntriesRequest {
	RequestId request_id = 7; 

	// Term in which the leader generating this request was elected.
	// REQUIRED
	Term term = 1;

	// Id of the leader server.
	// Generally this will be the id of the server than sent this request.
	// REQUIRED
	ServerId leader_id = 2; // < NOTE: For the bootstrapping process, this will be 0
	
	// Index of the log entry immediately before the first entry in 'entries'.
	// If 'entries' is empty, then this will be the index of the last entry appended to the
	// leader's log as of sending this request.
    // REQUIRED
	LogIndex prev_log_index = 3;
    
	// The term corresponding to the above prev_log_index.
	// REQUIRED
	Term prev_log_term = 4;

	// Entries to store in the recipient's log immediately after the entry at 'prev_log_index'.
	//
	// The recipient can ignore any entries already in it's local log at the same index and term,
	// then they can be ignored. 
	//
	// Assumptions:
	// The terms of these entries should be monotonic and the indexes should be sequential:
	// - prev_log_term <= entries[i].position.term <= term
	// - entries[0].position.index == prev_log_index + 1
	// - entries[i].position.index + 1 == entries[i+1].position.index
    repeated LogEntry entries = 5;
    
	// Index of the newest log index which has been commited by the leader (has been durably
	// flushed to a quorem of replicas).
	//
	// REQUIRED
	LogIndex leader_commit = 6;
}

message AppendEntriesResponse {
	// The request_id of the corresponding AppendEntriesRequest to which this is a response. 
	// REQUIRED
	RequestId request_id = 4;

	// Current term of the server producing this response.
	// REQUIRED
	Term term = 1;

	// Whether or not all the entries in the corresponding AppendEntriesRequest were able to be
	// successfully flushed to the server's log.
	// REQUIRED
	bool success = 2;

	// Index of the last log index in the server's log.
	// When success = false, this informs the leader that we can't send any entries with 

    // this is an addon to what is mentioned in the original research paper so
    // that the leader knows what it needs to replicate to this server
	//
	// OPTIONAL
    LogIndex last_log_index = 3;
}
/*
General alforithm:
- I don't really want the ConsensusModule to do RPC tracking
- But, I do want it to perform heartbeat tracking
- The server is free to partition the log entries however it wants. 
- It is convenient though to have the state in the ConsensusModule as it also 

AppendEntries{last, last + 1}
AppendEntries{last + 1, last + 2}
=> Realize that the follower's 

If I put all the log entry sizes into the Consensus module, then this would be a straight forward problem.
But I don't want the Consensus module to store a lot of data?
- This will just be 4 bytes per log entry so isn't all that big.
- 

So do I still need to track individual requests?
- Yes!!

General algorithm:
- Match index set to 0
- Start with the next_index set to 'last_leader_index + 1'
	- Assume leader is up to date with all followers
- We will send a heartbeat with prev index equal to 'last_leader_index'
	- For some servers, this may fail.
	- Next we will try to wind back the index to 'n - 1' or 'last_log_index' from the response
	- Mus mark as being in a failed state (we will disable pipelining until )

*/


// Upon being received a server should immediatley timeout and start its own
// election
message TimeoutNow {}

// Asks the server to propose a single entry to the state machine
message ProposeRequest {
	// REQUIRED
    LogEntryData data = 1;

    // If set, then this operation will block until the proposal has been
    // fulfilled or rejected
    // Otherwise the default behavior is to return a proposal that may
    // eventually get comitted or rejected
	//
	// REQUIRED
    bool wait = 2;
}

// XXX: Ideally should only be given as a response once the entries have been
// comitted
message ProposeResponse {
	oneof result {
		LogPosition proposal = 1;
		ProposeErrorProto error = 2;
	}
}

message LeaderHint {
	// REQUIRED
	Term term = 1;

	// OPTIONAL
	ServerId leader_id = 2;
}

message NotLeaderErrorProto {
	// OPTIONAL
	ServerId leader_hint = 1;
}

message ProposeErrorProto {
	oneof type {
		NotLeaderErrorProto not_leader = 1;
	}
}

// TODO: Assert that no server is ever both in the members and learners list at
// the same time (possibly convert to one single list and make the two
// categories purely getter methods for iterators)
message Configuration {
    // All servers in the cluster which participate in voting rounds. A majority of servers in this
    // list must vote the same way for a quorem to be achieved.
    repeated ServerId members = 1 [unordered_set = true];

    // All servers which do not participate in votes (at least not yet), but
    // should still be sent new entries
    repeated ServerId learners = 2 [unordered_set = true];
}

// Represents a configuration at a single index
message ConfigurationSnapshot {
    // Index of the last log entry applied to this configuration
    // REQUIRED
    LogIndex last_applied = 1;

    // Value of the snapshot at the given index (TODO: This is the only type
    // that actually needs to be serializiable, so it could be more verbose
    // for all I care)
    // REQUIRED
    Configuration data = 2;
}

message InstallSnapshotRequest {
	// Current term of the leader sending this request.
	// REQUIRED
	Term term = 1;

	// Id of the leader. Used to inform the follower of the current leader.
	// Currently this will always be set to the id of the server sending the request.
	// REQUIRED
	ServerId leader_id = 2; 

	// Position of the last log entry applied to the snapshot.
	//
	// TODO: Do we need this if the state machine snapshot encodes it?
	//
	// NOTE: This is sent only with the first chunk/request. 
	// REQUIRED
	LogPosition last_applied = 3;

	// Current configuration snapshot which is at least as far ahead as the state machine snapshot.
	//
	// NOTE: This is sent only with the first chunk/request.
	ConfigurationSnapshot last_config = 4;
	
	// Byte offset into the complete snapshot at which the data in this request is starting at.
	// Requests will always send contigious chunks with the offset always being equal to the last offset
	// sent in the previous request + 1, or 0 for the first request.
	//
	// REQUIRED
	uint64 offset = 5;

	// Chunk of data in the snapshot starting at 'offset' and ending at 'offset + data.len()'.
	//
	// REQUIRED
	bytes data = 6;

	// If this is the final chunk in the snapshot, this is set to true, else false.
	// REQUIRED
	bool done = 7;
}

message InstallSnapshotResponse {
	// Current term of the server receiving the snapshot.
	// REQUIRED
	Term term = 1;
}

message Status {
	ServerId id = 1;

	enum Role {
		UNKNOWN = 0;
		CANDIDATE = 1;
		FOLLOWER = 2;
		LEADER = 3;
	}
	Role role = 2;

	Metadata metadata = 3;

	Configuration configuration = 4;

	message FollowerProgress {
		ServerId id = 1;
		LogIndex match_index = 2;
	}

	// Only present if this is the leader.
	repeated FollowerProgress followers = 5;
}
